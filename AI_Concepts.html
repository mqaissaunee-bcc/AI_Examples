<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Top 20 AI Concepts - Interactive Learning</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(135deg, #8B5CF6 0%, #3B82F6 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }
        
        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            font-weight: 700;
        }
        
        .header p {
            font-size: 1.2rem;
            opacity: 0.9;
        }
        
        .grid-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            padding: 30px;
        }
        
        .concept-card {
            background: white;
            border: 2px solid #e5e7eb;
            border-radius: 15px;
            padding: 20px;
            cursor: pointer;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }
        
        .concept-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(0,0,0,0.15);
            border-color: #8B5CF6;
        }
        
        .concept-card.active {
            border-color: #8B5CF6;
            box-shadow: 0 0 0 3px rgba(139, 92, 246, 0.2);
        }
        
        .concept-number {
            position: absolute;
            top: -10px;
            left: -10px;
            background: #1f2937;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 1.1rem;
        }
        
        .concept-title {
            background: #fbbf24;
            color: #1f2937;
            padding: 8px 16px;
            border-radius: 20px;
            font-weight: bold;
            font-size: 1rem;
            margin: 10px 0 15px 0;
            display: inline-block;
        }
        
        .concept-icon {
            font-size: 3rem;
            margin: 15px 0;
            text-align: center;
            height: 80px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .concept-description {
            color: #6b7280;
            font-size: 0.95rem;
            line-height: 1.4;
        }
        
        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.8);
            backdrop-filter: blur(5px);
        }
        
        .modal-content {
            background-color: white;
            margin: 2% auto;
            padding: 0;
            border-radius: 20px;
            width: 90%;
            max-width: 800px;
            max-height: 90vh;
            overflow-y: auto;
            position: relative;
            animation: modalSlideIn 0.3s ease;
        }
        
        @keyframes modalSlideIn {
            from { transform: translateY(-50px); opacity: 0; }
            to { transform: translateY(0); opacity: 1; }
        }
        
        .modal-header {
            background: linear-gradient(135deg, #8B5CF6 0%, #3B82F6 100%);
            color: white;
            padding: 30px;
            border-radius: 20px 20px 0 0;
        }
        
        .modal-title {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: 10px;
        }
        
        .modal-subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
        }
        
        .modal-body {
            padding: 30px;
        }
        
        .close {
            position: absolute;
            right: 20px;
            top: 20px;
            color: white;
            font-size: 2rem;
            font-weight: bold;
            cursor: pointer;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: rgba(255,255,255,0.2);
            display: flex;
            align-items: center;
            justify-content: center;
            transition: background 0.3s ease;
        }
        
        .close:hover {
            background: rgba(255,255,255,0.3);
        }
        
        .lesson-section {
            margin-bottom: 25px;
        }
        
        .lesson-section h3 {
            color: #1f2937;
            font-size: 1.3rem;
            margin-bottom: 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid #e5e7eb;
        }
        
        .lesson-section p {
            color: #4b5563;
            line-height: 1.6;
            margin-bottom: 12px;
        }
        
        .example-box {
            background: #f3f4f6;
            border-left: 4px solid #8B5CF6;
            padding: 20px;
            margin: 15px 0;
            border-radius: 0 10px 10px 0;
        }
        
        .example-box h4 {
            color: #8B5CF6;
            margin-bottom: 10px;
            font-size: 1.1rem;
        }
        
        .key-points {
            background: #eff6ff;
            border: 1px solid #3b82f6;
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
        }
        
        .key-points h4 {
            color: #1e40af;
            margin-bottom: 10px;
        }
        
        .key-points ul {
            margin-left: 20px;
        }
        
        .key-points li {
            margin-bottom: 5px;
            color: #1e40af;
        }
        
        @media (max-width: 768px) {
            .grid-container {
                grid-template-columns: 1fr;
                padding: 20px;
            }
            
            .header h1 {
                font-size: 2rem;
            }
            
            .modal-content {
                width: 95%;
                margin: 5% auto;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üß† Top 20 AI Concepts</h1>
            <p>Interactive Learning Experience - Click any concept to dive deeper</p>
        </div>
        
        <div class="grid-container" id="conceptGrid">
            <!-- Concepts will be dynamically generated -->
        </div>
    </div>
    
    <!-- Modal -->
    <div id="conceptModal" class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <span class="close">&times;</span>
                <div class="modal-title" id="modalTitle"></div>
                <div class="modal-subtitle" id="modalSubtitle"></div>
            </div>
            <div class="modal-body" id="modalBody"></div>
        </div>
    </div>

    <script>
        const concepts = [
            {
                number: 1,
                title: "Machine Learning",
                icon: "ü§ñ",
                description: "Core algorithms, statistics, and model training techniques",
                lesson: {
                    subtitle: "The Foundation of Modern AI",
                    sections: [
                        {
                            title: "What is Machine Learning?",
                            content: "Machine Learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed for every task. Instead of following pre-written instructions, ML systems identify patterns in data and use these patterns to make predictions or decisions on new, unseen data."
                        },
                        {
                            title: "Core Components",
                            content: "Machine Learning involves three key elements: algorithms (the mathematical methods), data (the information used for training), and models (the trained systems that make predictions). The process typically involves training a model on historical data, validating its performance, and then deploying it to make predictions on new data."
                        },
                        {
                            title: "Types of Machine Learning",
                            content: "There are three main types: Supervised Learning (learning with labeled examples), Unsupervised Learning (finding patterns in unlabeled data), and Reinforcement Learning (learning through trial and error with rewards and penalties)."
                        }
                    ],
                    example: {
                        title: "Real-world Example",
                        content: "Email spam detection is a classic ML application. The system learns from thousands of emails labeled as 'spam' or 'not spam', identifying patterns like certain words, sender addresses, or formatting. Once trained, it can automatically classify new emails with high accuracy."
                    },
                    keyPoints: [
                        "Learns patterns from data automatically",
                        "Improves performance with more data",
                        "Foundation for most modern AI applications",
                        "Requires quality data for good results"
                    ]
                }
            },
            {
                number: 2,
                title: "Deep Learning",
                icon: "üß†",
                description: "Hierarchical neural networks learning complex representations automatically",
                lesson: {
                    subtitle: "Multi-layered Neural Networks",
                    sections: [
                        {
                            title: "Understanding Deep Learning",
                            content: "Deep Learning is a specialized subset of machine learning that uses artificial neural networks with multiple layers (hence 'deep') to model and understand complex patterns in data. These networks are inspired by how the human brain processes information through interconnected neurons."
                        },
                        {
                            title: "The Power of Layers",
                            content: "Each layer in a deep neural network learns increasingly complex features. The first layers might detect simple edges in images, middle layers identify shapes and textures, while deeper layers recognize complete objects like faces or cars. This hierarchical learning is what makes deep learning so powerful."
                        },
                        {
                            title: "Why Deep Learning Works",
                            content: "Deep learning excels at automatic feature extraction. Traditional machine learning often requires manual feature engineering, but deep learning automatically discovers the most relevant features from raw data. This makes it particularly effective for complex data like images, speech, and text."
                        }
                    ],
                    example: {
                        title: "Image Recognition Example",
                        content: "In medical imaging, deep learning models can analyze X-rays or MRI scans to detect diseases. The network learns to identify subtle patterns that might indicate conditions like pneumonia or tumors, often achieving accuracy levels comparable to or exceeding human specialists."
                    },
                    keyPoints: [
                        "Uses multiple layers of artificial neurons",
                        "Automatically learns complex features",
                        "Excels at pattern recognition in complex data",
                        "Requires large amounts of data and computational power"
                    ]
                }
            },
            {
                number: 3,
                title: "Neural Networks",
                icon: "üï∏Ô∏è",
                description: "Layered architectures efficiently model non-linear relationships accurately",
                lesson: {
                    subtitle: "The Building Blocks of AI",
                    sections: [
                        {
                            title: "Neural Network Basics",
                            content: "Neural networks are computing systems inspired by biological neural networks. They consist of interconnected nodes (neurons) that process and transmit information. Each connection has a weight that determines the strength of the signal passed between neurons."
                        },
                        {
                            title: "How They Learn",
                            content: "Neural networks learn through a process called backpropagation. During training, the network makes predictions, compares them to the correct answers, and adjusts the connection weights to reduce errors. This process repeats thousands of times until the network becomes accurate."
                        },
                        {
                            title: "Architecture Types",
                            content: "Different neural network architectures serve different purposes: Feedforward networks for basic classification, Convolutional Neural Networks (CNNs) for image processing, Recurrent Neural Networks (RNNs) for sequential data, and Transformer networks for language processing."
                        }
                    ],
                    example: {
                        title: "Voice Recognition",
                        content: "When you speak to Siri or Alexa, neural networks convert your voice into text. The network processes the audio waveform, identifies phonemes (basic speech sounds), combines them into words, and interprets the meaning - all in real-time."
                    },
                    keyPoints: [
                        "Inspired by biological brain structure",
                        "Learn through adjusting connection weights",
                        "Can model complex non-linear relationships",
                        "Foundation for most modern AI systems"
                    ]
                }
            },
            {
                number: 4,
                title: "NLP",
                icon: "üí¨",
                description: "Techniques to process and understand natural language complex text",
                lesson: {
                    subtitle: "Teaching Machines to Understand Language",
                    sections: [
                        {
                            title: "What is Natural Language Processing?",
                            content: "Natural Language Processing (NLP) is the field of AI that focuses on enabling computers to understand, interpret, and generate human language. It bridges the gap between human communication and computer understanding, allowing machines to process text and speech in meaningful ways."
                        },
                        {
                            title: "Core NLP Tasks",
                            content: "NLP encompasses various tasks including text classification (categorizing documents), named entity recognition (identifying people, places, organizations), sentiment analysis (determining emotional tone), machine translation (converting between languages), and text summarization."
                        },
                        {
                            title: "Challenges in NLP",
                            content: "Human language is inherently complex with ambiguity, context-dependence, idioms, and cultural nuances. NLP systems must handle these challenges while understanding grammar, semantics, and pragmatics - the study of language in context."
                        }
                    ],
                    example: {
                        title: "Customer Service Chatbots",
                        content: "Modern chatbots use NLP to understand customer queries, extract intent and entities, and provide relevant responses. They can handle multiple languages, understand context across conversation turns, and escalate complex issues to human agents when needed."
                    },
                    keyPoints: [
                        "Enables computers to process human language",
                        "Handles text analysis, generation, and translation",
                        "Requires understanding of context and meaning",
                        "Powers virtual assistants and translation services"
                    ]
                }
            },
            {
                number: 5,
                title: "Computer Vision",
                icon: "üëÅÔ∏è",
                description: "Algorithms interpreting and analyzing visual data effectively",
                lesson: {
                    subtitle: "Teaching Machines to See",
                    sections: [
                        {
                            title: "Computer Vision Fundamentals",
                            content: "Computer Vision enables machines to interpret and understand visual information from the world. It processes digital images and videos to extract meaningful information, identify objects, understand scenes, and make decisions based on visual input."
                        },
                        {
                            title: "Core Techniques",
                            content: "Computer vision uses various techniques including image preprocessing (noise reduction, enhancement), feature detection (edges, corners, textures), object detection and recognition, image segmentation (dividing images into regions), and 3D reconstruction."
                        },
                        {
                            title: "Modern Approaches",
                            content: "Contemporary computer vision heavily relies on deep learning, particularly Convolutional Neural Networks (CNNs). These networks can automatically learn visual features and achieve human-level performance in many vision tasks."
                        }
                    ],
                    example: {
                        title: "Autonomous Vehicles",
                        content: "Self-driving cars use computer vision to navigate roads safely. They identify lane markings, detect other vehicles, recognize traffic signs and signals, spot pedestrians, and assess road conditions - all in real-time to make driving decisions."
                    },
                    keyPoints: [
                        "Enables machines to interpret visual information",
                        "Uses deep learning for feature extraction",
                        "Applications in robotics, healthcare, security",
                        "Combines multiple visual processing techniques"
                    ]
                }
            },
            {
                number: 6,
                title: "Reinforcement Learning",
                icon: "üéØ",
                description: "Agent learns optimal behavior through interaction with environment",
                lesson: {
                    subtitle: "Learning Through Trial and Error",
                    sections: [
                        {
                            title: "Reinforcement Learning Principles",
                            content: "Reinforcement Learning (RL) is a machine learning paradigm where an agent learns to make decisions by interacting with an environment. The agent receives rewards or penalties based on its actions and learns to maximize cumulative rewards over time through trial and error."
                        },
                        {
                            title: "Key Components",
                            content: "RL systems consist of an agent (the learner), an environment (the world the agent interacts with), actions (choices the agent can make), states (situations the agent can be in), and rewards (feedback signals). The agent's goal is to learn an optimal policy - a strategy for choosing actions."
                        },
                        {
                            title: "Learning Process",
                            content: "The agent starts with random actions and gradually improves through experience. It uses techniques like Q-learning or policy gradients to update its decision-making strategy based on the rewards received. Over time, it learns which actions lead to better outcomes in different situations."
                        }
                    ],
                    example: {
                        title: "Game Playing AI",
                        content: "AlphaGo, the AI that defeated world champions in Go, used reinforcement learning. It played millions of games against itself, learning from wins and losses. Each game provided feedback that helped it develop increasingly sophisticated strategies."
                    },
                    keyPoints: [
                        "Learns optimal behavior through interaction",
                        "Uses rewards and penalties as feedback",
                        "Excellent for sequential decision-making",
                        "Applications in robotics, game AI, and optimization"
                    ]
                }
            },
            {
                number: 7,
                title: "Generative Models",
                icon: "üé®",
                description: "Creating new data samples using learned distributions",
                lesson: {
                    subtitle: "AI That Creates Original Content",
                    sections: [
                        {
                            title: "Understanding Generative Models",
                            content: "Generative models are AI systems that learn to create new data that resembles the training data. Unlike discriminative models that classify or predict, generative models understand the underlying patterns in data well enough to produce realistic new examples."
                        },
                        {
                            title: "Types of Generative Models",
                            content: "Major types include Generative Adversarial Networks (GANs) where two networks compete to create realistic data, Variational Autoencoders (VAEs) that learn compressed representations, and autoregressive models that generate data sequentially."
                        },
                        {
                            title: "How They Work",
                            content: "Generative models learn the probability distribution of the training data. They can then sample from this learned distribution to create new, similar data. The key is learning not just what the data looks like, but understanding the underlying structure and patterns."
                        }
                    ],
                    example: {
                        title: "AI Art Generation",
                        content: "Tools like DALL-E and Midjourney use generative models to create original artwork from text descriptions. They've learned patterns from millions of images and can combine concepts in novel ways, creating art that has never existed before but looks realistic."
                    },
                    keyPoints: [
                        "Creates new, original content",
                        "Learns underlying data distributions",
                        "Applications in art, music, text, and synthetic data",
                        "Includes GANs, VAEs, and diffusion models"
                    ]
                }
            },
            {
                number: 8,
                title: "LLM",
                icon: "üåä",
                description: "Generates human-like text using massive pre-training data",
                lesson: {
                    subtitle: "Large Language Models Revolution",
                    sections: [
                        {
                            title: "What are Large Language Models?",
                            content: "Large Language Models (LLMs) are AI systems trained on vast amounts of text data to understand and generate human-like language. They use transformer architecture and contain billions of parameters, enabling them to perform various language tasks with remarkable capability."
                        },
                        {
                            title: "Training Process",
                            content: "LLMs are trained in two main phases: pre-training on massive text corpora where they learn language patterns, and fine-tuning on specific tasks or with human feedback to improve performance and alignment with human preferences."
                        },
                        {
                            title: "Capabilities and Applications",
                            content: "Modern LLMs can engage in conversations, write code, analyze documents, translate languages, summarize content, and reason through complex problems. They exhibit emergent behaviors not explicitly trained for, showing a form of general intelligence."
                        }
                    ],
                    example: {
                        title: "ChatGPT and Similar Systems",
                        content: "ChatGPT demonstrates LLM capabilities by maintaining coherent conversations, answering questions across diverse topics, helping with coding problems, and assisting with creative writing - all through natural language interaction."
                    },
                    keyPoints: [
                        "Trained on massive text datasets",
                        "Can perform diverse language tasks",
                        "Show emergent reasoning capabilities",
                        "Foundation for conversational AI"
                    ]
                }
            },
            {
                number: 9,
                title: "Transformers",
                icon: "‚ö°",
                description: "Self-attention-based architecture powering modern AI models",
                lesson: {
                    subtitle: "The Architecture That Changed AI",
                    sections: [
                        {
                            title: "Transformer Architecture",
                            content: "Transformers are a neural network architecture that revolutionized AI by using self-attention mechanisms instead of recurrent connections. They can process all positions in a sequence simultaneously, making them more efficient and effective for language tasks."
                        },
                        {
                            title: "Self-Attention Mechanism",
                            content: "Self-attention allows the model to relate different positions in a sequence to compute representations. When processing a word, the model can attend to all other words in the sentence, understanding context and relationships regardless of distance."
                        },
                        {
                            title: "Impact on AI",
                            content: "Transformers enabled the development of large language models like GPT and BERT. Their parallel processing capabilities and ability to capture long-range dependencies made them the foundation for most modern NLP breakthroughs."
                        }
                    ],
                    example: {
                        title: "Machine Translation",
                        content: "Google Translate uses transformer models that can translate between languages by understanding the meaning and context of entire sentences, rather than translating word-by-word. This produces more natural and accurate translations."
                    },
                    keyPoints: [
                        "Uses self-attention instead of recurrence",
                        "Processes sequences in parallel",
                        "Foundation for GPT, BERT, and similar models",
                        "Revolutionized natural language processing"
                    ]
                }
            },
            {
                number: 10,
                title: "Feature Engineering",
                icon: "üîß",
                description: "Designing informative features significantly improving model performance",
                lesson: {
                    subtitle: "Crafting Better Input Data",
                    sections: [
                        {
                            title: "What is Feature Engineering?",
                            content: "Feature engineering is the process of selecting, modifying, or creating new features (input variables) from raw data to improve machine learning model performance. It's often considered more art than science, requiring domain expertise and creativity."
                        },
                        {
                            title: "Common Techniques",
                            content: "Techniques include normalization (scaling features to similar ranges), encoding categorical variables, creating polynomial features, extracting features from dates/times, handling missing values, and dimensionality reduction to remove irrelevant features."
                        },
                        {
                            title: "Impact on Model Performance",
                            content: "Good feature engineering can dramatically improve model accuracy, even with simple algorithms. It helps models learn more effectively by providing relevant, clean, and well-structured information that highlights important patterns in the data."
                        }
                    ],
                    example: {
                        title: "Predicting House Prices",
                        content: "Instead of just using raw features like 'year built', feature engineering might create 'house age', 'years since renovation', or 'price per square foot'. These derived features often provide more meaningful information for the prediction task."
                    },
                    keyPoints: [
                        "Transforms raw data into useful features",
                        "Requires domain knowledge and creativity",
                        "Can significantly improve model performance",
                        "Less critical with deep learning but still important"
                    ]
                }
            },
            {
                number: 11,
                title: "Supervised Learning",
                icon: "üìö",
                description: "Learns useful representations without labeled data",
                lesson: {
                    subtitle: "Learning with Labeled Examples",
                    sections: [
                        {
                            title: "Supervised Learning Fundamentals",
                            content: "Supervised learning uses labeled training data to learn a mapping from inputs to outputs. The algorithm learns from examples where both the input and the correct answer (label) are provided, allowing it to make predictions on new, unseen data."
                        },
                        {
                            title: "Types of Supervised Learning",
                            content: "Classification tasks predict discrete categories (email is spam or not spam), while regression tasks predict continuous values (house prices, stock prices). Both use labeled training data but have different output types and evaluation metrics."
                        },
                        {
                            title: "Common Algorithms",
                            content: "Popular supervised learning algorithms include linear regression, decision trees, random forests, support vector machines, and neural networks. Each has strengths and weaknesses depending on the data type and problem complexity."
                        }
                    ],
                    example: {
                        title: "Medical Diagnosis",
                        content: "Supervised learning can help diagnose diseases by training on medical records with known diagnoses. The system learns patterns between symptoms, test results, and diagnoses, then can suggest diagnoses for new patients based on their symptoms."
                    },
                    keyPoints: [
                        "Uses labeled training data",
                        "Includes classification and regression tasks",
                        "Most common machine learning approach",
                        "Requires quality labeled examples for training"
                    ]
                }
            },
            {
                number: 12,
                title: "Bayesian Learning",
                icon: "üìä",
                description: "Incorporates uncertainty using probabilistic model approaches",
                lesson: {
                    subtitle: "Probabilistic Approach to Learning",
                    sections: [
                        {
                            title: "Bayesian Learning Principles",
                            content: "Bayesian learning incorporates uncertainty and prior knowledge into machine learning. It uses Bayes' theorem to update beliefs about model parameters as new data arrives, providing not just predictions but also confidence estimates."
                        },
                        {
                            title: "Prior Knowledge Integration",
                            content: "Unlike other approaches, Bayesian methods can incorporate existing knowledge through prior distributions. This is especially valuable when data is limited or when domain expertise suggests certain parameter values are more likely."
                        },
                        {
                            title: "Uncertainty Quantification",
                            content: "Bayesian models provide uncertainty estimates with their predictions. Instead of just saying 'the price will be $100K', they might say 'the price will be $100K with 95% confidence interval of $90K-$110K', which is valuable for decision-making."
                        }
                    ],
                    example: {
                        title: "Drug Discovery",
                        content: "In pharmaceutical research, Bayesian methods help optimize drug trials by incorporating prior knowledge about similar compounds and continuously updating beliefs about drug effectiveness as trial data becomes available."
                    },
                    keyPoints: [
                        "Incorporates prior knowledge and uncertainty",
                        "Provides confidence estimates with predictions",
                        "Updates beliefs as new data arrives",
                        "Valuable when data is limited or noisy"
                    ]
                }
            },
            {
                number: 13,
                title: "Prompt Engineering",
                icon: "‚úçÔ∏è",
                description: "Crafting effective inputs to guide generative model outputs",
                lesson: {
                    subtitle: "The Art of Communicating with AI",
                    sections: [
                        {
                            title: "What is Prompt Engineering?",
                            content: "Prompt engineering is the practice of designing and optimizing input prompts to get desired outputs from AI models, particularly large language models. It's the interface between human intent and AI capability, requiring both technical understanding and creative communication."
                        },
                        {
                            title: "Effective Prompt Strategies",
                            content: "Good prompts are clear, specific, and provide context. Techniques include few-shot learning (providing examples), chain-of-thought prompting (asking for step-by-step reasoning), and role-playing (asking the AI to adopt a specific persona or expertise)."
                        },
                        {
                            title: "Advanced Techniques",
                            content: "Advanced prompt engineering includes prompt chaining (breaking complex tasks into steps), temperature control (adjusting randomness), and prompt optimization (systematically testing and refining prompts for better performance)."
                        }
                    ],
                    example: {
                        title: "Code Generation",
                        content: "Instead of asking 'write code for a website', an effective prompt might be: 'Create a responsive HTML/CSS webpage for a bakery with a header, menu section, and contact form. Use modern CSS Grid layout and include hover effects on menu items.'"
                    },
                    keyPoints: [
                        "Critical skill for working with LLMs",
                        "Combines technical knowledge with communication",
                        "Can dramatically improve AI output quality",
                        "Involves iterative testing and refinement"
                    ]
                }
            },
            {
                number: 14,
                title: "AI Agents",
                icon: "ü§ñ",
                description: "Autonomous systems that perceive, decide, and act",
                lesson: {
                    subtitle: "AI That Takes Action",
                    sections: [
                        {
                            title: "Understanding AI Agents",
                            content: "AI agents are autonomous systems that can perceive their environment, make decisions, and take actions to achieve specific goals. Unlike passive AI models that only respond to inputs, agents actively interact with their environment and can adapt their behavior based on outcomes."
                        },
                        {
                            title: "Agent Components",
                            content: "AI agents typically include sensors (to perceive the environment), actuators (to take actions), a knowledge base (stored information), and decision-making algorithms (to choose appropriate actions). They also have goals or objectives that guide their behavior."
                        },
                        {
                            title: "Types of AI Agents",
                            content: "Agents can be reactive (responding to immediate stimuli), deliberative (planning ahead), or hybrid (combining both approaches). They can operate in single-agent environments or multi-agent systems where multiple agents interact and potentially collaborate or compete."
                        }
                    ],
                    example: {
                        title: "Virtual Assistants",
                        content: "Siri, Alexa, and Google Assistant are AI agents that perceive voice commands, understand intent, access knowledge bases, make decisions about how to respond, and take actions like setting reminders, playing music, or controlling smart home devices."
                    },
                    keyPoints: [
                        "Autonomous systems that act in environments",
                        "Combine perception, decision-making, and action",
                        "Can adapt behavior based on outcomes",
                        "Applications in robotics, virtual assistants, and automation"
                    ]
                }
            },
            {
                number: 15,
                title: "Fine Tuning Models",
                icon: "‚öôÔ∏è",
                description: "Customizes pre-trained models for domain-specific tasks",
                lesson: {
                    subtitle: "Adapting Pre-trained Models",
                    sections: [
                        {
                            title: "Understanding Fine-Tuning",
                            content: "Fine-tuning is the process of taking a pre-trained model and adapting it for a specific task or domain. Instead of training from scratch, fine-tuning leverages the general knowledge already learned by the model and specializes it for particular applications."
                        },
                        {
                            title: "The Fine-Tuning Process",
                            content: "Fine-tuning typically involves taking a model trained on a large, general dataset and continuing training on a smaller, task-specific dataset. The learning rate is usually lower than initial training to preserve the general knowledge while adapting to the new task."
                        },
                        {
                            title: "Benefits and Applications",
                            content: "Fine-tuning is more efficient than training from scratch, requires less data, and often achieves better performance. It's commonly used in computer vision (adapting image classifiers), NLP (customizing language models), and many other domains where pre-trained models exist."
                        }
                    ],
                    example: {
                        title: "Medical Image Analysis",
                        content: "A model pre-trained on general images can be fine-tuned on medical scans to detect specific diseases. The pre-trained model already understands basic visual features, so fine-tuning teaches it to recognize medical-specific patterns like tumors or fractures."
                    },
                    keyPoints: [
                        "Adapts pre-trained models to specific tasks",
                        "More efficient than training from scratch",
                        "Requires less task-specific data",
                        "Widely used in computer vision and NLP"
                    ]
                }
            },
            {
                number: 16,
                title: "Multimodal Models",
                icon: "üé≠",
                description: "Processes and generates across multiple data types",
                lesson: {
                    subtitle: "AI That Understands Multiple Modalities",
                    sections: [
                        {
                            title: "What are Multimodal Models?",
                            content: "Multimodal models can process and understand multiple types of data simultaneously, such as text, images, audio, and video. They bridge different modalities to create more comprehensive AI systems that can understand the world more like humans do."
                        },
                        {
                            title: "Cross-Modal Understanding",
                            content: "These models learn relationships between different modalities. For example, they can understand that a picture of a dog relates to the word 'dog' and the sound of barking. This cross-modal understanding enables more sophisticated AI applications."
                        },
                        {
                            title: "Architecture and Training",
                            content: "Multimodal models often use shared representations where different modalities are mapped to a common embedding space. Training involves learning from paired data across modalities, such as images with captions or videos with audio descriptions."
                        }
                    ],
                    example: {
                        title: "Image Captioning and Visual Question Answering",
                        content: "GPT-4 with vision can look at an image and answer questions about it or generate detailed descriptions. It combines computer vision capabilities with language understanding to bridge the gap between visual and textual information."
                    },
                    keyPoints: [
                        "Processes multiple data types simultaneously",
                        "Learns relationships between modalities",
                        "Enables more natural human-AI interaction",
                        "Applications in robotics, content creation, and accessibility"
                    ]
                }
            },
            {
                number: 17,
                title: "Embeddings",
                icon: "üîó",
                description: "Transforms input into machine-readable vector formats",
                lesson: {
                    subtitle: "Converting Data to Mathematical Representations",
                    sections: [
                        {
                            title: "Understanding Embeddings",
                            content: "Embeddings are dense vector representations of data that capture semantic meaning in a mathematical form. They convert discrete items like words, images, or users into continuous vectors where similar items are positioned close together in the vector space."
                        },
                        {
                            title: "How Embeddings Work",
                            content: "Embeddings are learned through training processes where neural networks map input data to fixed-size vectors. The key insight is that similar items should have similar vector representations, enabling mathematical operations to capture semantic relationships."
                        },
                        {
                            title: "Types and Applications",
                            content: "Word embeddings represent words as vectors, image embeddings capture visual features, and user embeddings model preferences. These representations enable similarity search, clustering, recommendation systems, and transfer learning across different tasks."
                        }
                    ],
                    example: {
                        title: "Word Embeddings in Search",
                        content: "When you search for 'puppy', systems using word embeddings can also return results for 'dog', 'canine', or 'pet' because these words have similar vector representations, even though they don't share exact text matches."
                    },
                    keyPoints: [
                        "Convert discrete data to continuous vectors",
                        "Capture semantic similarity mathematically",
                        "Enable efficient similarity search and clustering",
                        "Foundation for many modern AI applications"
                    ]
                }
            },
            {
                number: 18,
                title: "Vector Search",
                icon: "üîç",
                description: "Finds similar items using dense vector embeddings",
                lesson: {
                    subtitle: "Semantic Search Through Vector Space",
                    sections: [
                        {
                            title: "Vector Search Fundamentals",
                            content: "Vector search uses embeddings to find similar items by measuring distances or similarities between vectors in high-dimensional space. Unlike traditional keyword search, vector search can find semantically similar content even when exact words don't match."
                        },
                        {
                            title: "Distance Metrics",
                            content: "Common distance metrics include cosine similarity (measuring angle between vectors), Euclidean distance (straight-line distance), and dot product similarity. Each metric captures different aspects of similarity and is chosen based on the specific use case."
                        },
                        {
                            title: "Scalability and Optimization",
                            content: "For large datasets, exact vector search becomes computationally expensive. Approximate methods like LSH (Locality-Sensitive Hashing), HNSW (Hierarchical Navigable Small World), and specialized vector databases enable fast similarity search at scale."
                        }
                    ],
                    example: {
                        title: "Recommendation Systems",
                        content: "Spotify uses vector search to recommend music by converting songs into embeddings that capture musical features like genre, tempo, and mood. When you like a song, the system finds other songs with similar vectors to recommend."
                    },
                    keyPoints: [
                        "Enables semantic similarity search",
                        "Works with high-dimensional vector spaces",
                        "Requires efficient algorithms for scale",
                        "Powers recommendation and retrieval systems"
                    ]
                }
            },
            {
                number: 19,
                title: "Model Evaluation",
                icon: "üìà",
                description: "Assessing predictive performance using validation techniques",
                lesson: {
                    subtitle: "Measuring AI Model Performance",
                    sections: [
                        {
                            title: "Why Model Evaluation Matters",
                            content: "Model evaluation is crucial for understanding how well an AI system performs on unseen data. It helps identify overfitting, compare different models, and ensure the model meets performance requirements before deployment in real-world applications."
                        },
                        {
                            title: "Evaluation Metrics",
                            content: "Different tasks require different metrics: accuracy and F1-score for classification, RMSE and MAE for regression, BLEU scores for translation, and perplexity for language models. The choice of metric depends on the specific problem and business requirements."
                        },
                        {
                            title: "Validation Techniques",
                            content: "Cross-validation splits data into multiple folds for robust evaluation. Hold-out validation reserves a test set that's never seen during training. Time-series validation respects temporal order. These techniques help estimate how the model will perform on new data."
                        }
                    ],
                    example: {
                        title: "Medical AI Validation",
                        content: "Before deploying an AI system to diagnose medical conditions, it must be rigorously evaluated on diverse patient populations, with metrics like sensitivity (catching true positives) and specificity (avoiding false positives) carefully measured."
                    },
                    keyPoints: [
                        "Essential for understanding model performance",
                        "Uses different metrics for different tasks",
                        "Includes techniques like cross-validation",
                        "Critical for deployment decisions"
                    ]
                }
            },
            {
                number: 20,
                title: "AI Infrastructure",
                icon: "‚òÅÔ∏è",
                description: "Deploying scalable systems to support AI operations",
                lesson: {
                    subtitle: "Building Systems That Support AI",
                    sections: [
                        {
                            title: "AI Infrastructure Components",
                            content: "AI infrastructure includes the hardware (GPUs, TPUs, CPUs), software frameworks (TensorFlow, PyTorch), data storage systems, model serving platforms, and monitoring tools needed to develop, train, and deploy AI models at scale."
                        },
                        {
                            title: "Scalability Challenges",
                            content: "AI workloads require significant computational resources and can be unpredictable. Infrastructure must handle training large models, serving predictions at low latency, managing large datasets, and scaling up or down based on demand."
                        },
                        {
                            title: "MLOps and Model Lifecycle",
                            content: "Modern AI infrastructure includes MLOps practices for versioning models, automating training pipelines, continuous integration/deployment, model monitoring, and managing the entire machine learning lifecycle from development to production."
                        }
                    ],
                    example: {
                        title: "Cloud AI Services",
                        content: "Companies like Google Cloud, AWS, and Azure provide AI infrastructure including pre-trained models, training environments, model serving endpoints, and monitoring tools, allowing organizations to focus on their specific AI applications rather than infrastructure management."
                    },
                    keyPoints: [
                        "Combines hardware, software, and operational practices",
                        "Must handle large-scale, resource-intensive workloads",
                        "Includes MLOps for model lifecycle management",
                        "Often leverages cloud platforms for scalability"
                    ]
                }
            }
        ];

        // Generate concept cards
        function generateConceptCards() {
            const grid = document.getElementById('conceptGrid');
            
            concepts.forEach(concept => {
                const card = document.createElement('div');
                card.className = 'concept-card';
                card.onclick = () => openModal(concept);
                
                card.innerHTML = `
                    <div class="concept-number">${concept.number}</div>
                    <div class="concept-title">${concept.title}</div>
                    <div class="concept-icon">${concept.icon}</div>
                    <div class="concept-description">${concept.description}</div>
                `;
                
                grid.appendChild(card);
            });
        }

        // Open modal with lesson content
        function openModal(concept) {
            const modal = document.getElementById('conceptModal');
            const modalTitle = document.getElementById('modalTitle');
            const modalSubtitle = document.getElementById('modalSubtitle');
            const modalBody = document.getElementById('modalBody');
            
            modalTitle.textContent = concept.title;
            modalSubtitle.textContent = concept.lesson.subtitle;
            
            let bodyContent = '';
            
            // Add lesson sections
            concept.lesson.sections.forEach(section => {
                bodyContent += `
                    <div class="lesson-section">
                        <h3>${section.title}</h3>
                        <p>${section.content}</p>
                    </div>
                `;
            });
            
            // Add example
            if (concept.lesson.example) {
                bodyContent += `
                    <div class="example-box">
                        <h4>${concept.lesson.example.title}</h4>
                        <p>${concept.lesson.example.content}</p>
                    </div>
                `;
            }
            
            // Add key points
            if (concept.lesson.keyPoints) {
                bodyContent += `
                    <div class="key-points">
                        <h4>Key Takeaways</h4>
                        <ul>
                            ${concept.lesson.keyPoints.map(point => `<li>${point}</li>`).join('')}
                        </ul>
                    </div>
                `;
            }
            
            modalBody.innerHTML = bodyContent;
            modal.style.display = 'block';
            document.body.style.overflow = 'hidden';
        }

        // Close modal
        function closeModal() {
            const modal = document.getElementById('conceptModal');
            modal.style.display = 'none';
            document.body.style.overflow = 'auto';
        }

        // Event listeners
        document.addEventListener('DOMContentLoaded', function() {
            generateConceptCards();
            
            // Close modal when clicking X
            document.querySelector('.close').onclick = closeModal;
            
            // Close modal when clicking outside
            window.onclick = function(event) {
                const modal = document.getElementById('conceptModal');
                if (event.target === modal) {
                    closeModal();
                }
            };
            
            // Close modal with Escape key
            document.addEventListener('keydown', function(event) {
                if (event.key === 'Escape') {
                    closeModal();
                }
            });
        });
    </script>
</body>
</html>